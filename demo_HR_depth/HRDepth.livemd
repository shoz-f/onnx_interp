# Monocular Depth Estimation: HR-Depth

```elixir
File.cd!(__DIR__)
# for windows JP
# System.shell("chcp 65001")

Mix.install([
  {:onnx_interp, "~> 0.1.8"},
  {:cimg, "~> 0.1.18"},
  {:nx, "~> 0.4.2"},
  {:kino, "~> 0.8.0"}
])
```

## 0.Original work

HR-Depth: High Resolution Self-Supervised Monocular Depth Estimation

* https://arxiv.org/abs/2012.07356

GitHub: HR-Depth: High Resolution Self-Supervised Monocular Depth Estimation

* https://github.com/shawLyu/HR-Depth

This note usee the pretraind model converted from above project ;-)

***Thanks a lot!!!***

---

## Implementation with OnnxInterp in Elixir

## 1.Defining the inference module: HRDepthEncoder

* Model<br>
  sc_depth-epoch=99-val_loss=0.1438.onnx

* Pre-processing<br>
  Resize the input image to the size {640,384}, gauss {{114.75,57.375},{114.75,57.375},{114.75,57.375}}} and transpose NCHW.

* Post-processing<br>
  normalize depth map and color-mapping.

```elixir
defmodule HRDepthEncoder do
  @width  1280
  @height 384

  alias OnnxInterp, as: NNInterp
  use NNInterp,
    model: "model/HR_Depth_K_M_1280x384_encoder.onnx",
    url: "https://github.com/shoz-f/onnx_interp/releases/download/models/HR_Depth_K_M_1280x384_encoder.onnx",
    inputs: [f32: {1,3,@height,@width}],
    outputs: [f32: {1,64,192,640}, f32: {1,64,96,320}, f32: {1,128,48,160}, f32: {1,256,24,80}, f32: {1,512,12,40}]

  def apply(img) do
    # preprocess
    input0 = img
      |> CImg.resize({@width, @height})
      |> CImg.to_binary([{:range, {0.0, 1.0}}, :nchw])

    # prediction
    session()
    |> NNInterp.set_input_tensor(0, input0)
    |> NNInterp.invoke()
    |> get_output_tensors(0..4)
  end

  def get_output_tensors(session, range) do
    for i <- range, do: NNInterp.get_output_tensor(session, i)
  end
end
```

## 2.Defining the inference module: HRDepthDecoder

* Model<br>
  sc_depth-epoch=99-val_loss=0.1438.onnx

* Pre-processing<br>
  Resize the input image to the size {640,384}, gauss {{114.75,57.375},{114.75,57.375},{114.75,57.375}}} and transpose NCHW.

* Post-processing<br>
  normalize depth map and color-mapping.

```elixir
defmodule HRDepthDecoder do
  @width  1280
  @height 384

  alias OnnxInterp, as: NNInterp
  use NNInterp,
    model: "model/HR_Depth_K_M_1280x384_decoder.onnx",
    url: "https://github.com/shoz-f/onnx_interp/releases/download/models/HR_Depth_K_M_1280x384_decoder.onnx",
    inputs: [f32: {1,64,192,640}, f32: {1,64,96,320}, f32: {1,128,48,160}, f32: {1,256,24,80}, f32: {1,512,12,40}],
    outputs: [f32: {1,1,@height,@width}, f32: {1,1,192,640}, f32: {1,1,96,320}, f32: {1,1,48,160}]

  def apply(inputs) do
    # prediction
    output0 = session()
      |> set_input_tensors(inputs)
      |> NNInterp.invoke()
      |> NNInterp.get_output_tensor(0)

    # postprocess
    CImg.from_binary(output0, @width, @height, 1, 1, range: min_max(output0), dtype: "<f4")
  end

  def set_input_tensors(session, items, offset \\ 0) when is_list(items) do
    Enum.with_index(items, offset)
    |> Enum.reduce(session, fn {item, i}, session -> NNInterp.set_input_tensor(session, i, item) end)
  end

  defp min_max(bin) do
    t = Nx.from_binary(bin, :f32)
    {
      Nx.reduce_min(t) |> Nx.to_number(),
      Nx.reduce_max(t) |> Nx.to_number()
    }
  end
end
```

```elixir
defmodule HRDepth do
  def apply(img) do
    img
    |> HRDepthEncoder.apply()
    |> HRDepthDecoder.apply()
  end
end
```

Launch `HRDepth`.

```elixir
# OnnxInterp.stop(HRDepthEncoder)
HRDepthEncoder.start_link([])
# OnnxInterp.stop(HRDepthDecoder)
HRDepthDecoder.start_link([])
```

Display the properties of the `ScDepth` model.

```elixir
OnnxInterp.info(HRDepthEncoder)
```

```elixir
OnnxInterp.info(HRDepthDecoder)
```

## 2.Defining execution module HRDepth

```elixir
defmodule LiveHRDepth do
  def run(path) do
    img = CImg.load(path)

    depth = HRDepth.apply(img)
    #      |> CImg.color_mapping(:jet)

    #    Kino.Layout.grid(
    #      Enum.map([img, depth], &CImg.display_kino(&1, :jpeg)),
    #      columns: 2
    #    )
  end
end
```

## 3.Let's try it

```elixir
dat = LiveHRDepth.run("sample.jpg")
```

```elixir
Nx.from_binary(dat, :f32) |> Nx.reduce_min()
```

## Appendix

[1] export_onnx.py: python script to convert Pytorch checkpoint to ONNX.

```python:export_onnx.py
import torch
import torch.onnx
from path import Path
import os

from config import get_opts, get_training_size

from SC_Depth import SC_Depth
from SC_DepthV2 import SC_DepthV2
from SC_DepthV3 import SC_DepthV3


@torch.no_grad()
def main():
    hparams = get_opts()

    if hparams.model_version == 'v1':
        system = SC_Depth(hparams)
    elif hparams.model_version == 'v2':
        system = SC_DepthV2(hparams)
    elif hparams.model_version == 'v3':
        system = SC_DepthV3(hparams)

    output_dir = Path(hparams.output_dir)
    output_dir.makedirs_p()

    system = system.load_from_checkpoint(hparams.ckpt_path, strict=False)

    model = system.depth_net
    model.eval()

    # training size
    training_size = get_training_size(hparams.dataset_name)
    dummy_input = torch.randn(1, 3, *training_size)

    # export the model
    torch.onnx.export(model,
        dummy_input,
        output_dir / Path(hparams.ckpt_path).stem + ".onnx",
        export_params=True,
        #opset_version=10,
        do_constant_folding=True,
        input_names=["input.0"],
        output_names=["output.0"],
        #dynamic_axes={}
        )


if __name__ == '__main__':
    main()

```

<!-- livebook:{"break_markdown":true} -->

&#9633;
